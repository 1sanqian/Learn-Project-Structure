# **[LangChain å®˜æ–¹æ–‡æ¡£ï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰](https://docs.langchain.com)**

+ å…³é”®æ¨¡å—è¦ç‚¹ï¼š
 LLMChainï¼šåŸºç¡€é“¾
PromptTemplateï¼šæç¤ºè¯æ¨¡æ¿
ConversationChainï¼šå¯¹è¯é“¾
RetrievalQAï¼šæ–‡æ¡£é—®ç­”å…¥å£
VectorStoreï¼šå‘é‡åº“ï¼ˆä¾‹å¦‚ FAISSï¼‰

+ [RAG æ•™ç¨‹](https://python.langchain.com/v0.1/docs/use_cases/question_answering/)
 ## ğŸŒŸ1. LLMChainï¼šåŸºç¡€é“¾

è¿™æ˜¯æœ€åŸºç¡€çš„â€œé“¾â€ï¼ŒåŠŸèƒ½æ˜¯ï¼š
ğŸ‘‰ ç”¨æç¤ºè¯ï¼ˆPromptï¼‰ + LLMï¼ˆå¤§æ¨¡å‹ï¼‰æ¥ç”Ÿæˆç­”æ¡ˆã€‚

ğŸ“¦ æ„æˆï¼š
PromptTemplateï¼ˆæç¤ºè¯æ¨¡æ¿ï¼‰
LLMï¼ˆæ¯”å¦‚ OpenAIã€é€šä¹‰åƒé—®ã€ChatGLM ç­‰ï¼‰
LLMChain = æŠŠä¸Šé¢ä¸¤ä¸ªç»„åˆèµ·æ¥è¿è¡Œ

ğŸ“Œ ç¤ºä¾‹ä»£ç ï¼š
```
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# å®šä¹‰æç¤ºè¯æ¨¡æ¿
template = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»{topic}"
prompt = PromptTemplate.from_template(template)

# ä½¿ç”¨ OpenAI ä½œä¸ºè¯­è¨€æ¨¡å‹
llm = OpenAI(temperature=0.7)

# æ„å»º LLMChain
chain = LLMChain(prompt=prompt, llm=llm)

# æ‰§è¡Œ
result = chain.run("äººå·¥æ™ºèƒ½")
print(result)
```

## ğŸ§© 2. PromptTemplateï¼šæç¤ºè¯æ¨¡æ¿

ğŸ‘‰ å°±æ˜¯â€œç»™å¤§æ¨¡å‹è¯´è¯ç”¨çš„æç¤ºè¯â€ï¼Œåƒä½ å¹³æ—¶å’Œæˆ‘è¯´ï¼šâ€œè¯·ç”Ÿæˆä¸€æ®µä»‹ç»xxçš„æ–‡å­—â€ã€‚

ğŸ“Œ ç¤ºä¾‹ä»£ç ï¼š
```
from langchain.prompts import PromptTemplate

template = "è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯{concept}ã€‚"
prompt = PromptTemplate.from_template(template)

# æ›¿æ¢æ¨¡æ¿å˜é‡
print(prompt.format(concept="é‡å­è®¡ç®—"))
```

## ğŸ—£ï¸ 3. ConversationChainï¼šå¯¹è¯é“¾

ğŸ‘‰ è®©æ¨¡å‹å¯ä»¥è®°ä½ä½ ä¹‹å‰è¯´è¿‡ä»€ä¹ˆï¼Œå½¢æˆä¸Šä¸‹æ–‡è¿ç»­çš„å¯¹è¯ã€‚

ğŸ“Œ ç¤ºä¾‹ä»£ç ï¼š
```
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.llms import OpenAI

llm = OpenAI()
memory = ConversationBufferMemory()

conversation = ConversationChain(llm=llm, memory=memory)

print(conversation.run("ä½ å¥½ï¼"))
print(conversation.run("æˆ‘æƒ³äº†è§£äººå·¥æ™ºèƒ½ã€‚"))
print(conversation.run("å®ƒä¼šå–ä»£äººç±»å·¥ä½œå—ï¼Ÿ"))
```

## ğŸ“„ 4. RetrievalQAï¼šæ–‡æ¡£é—®ç­”é“¾

ğŸ‘‰ æŠŠæœ¬åœ°æ–‡æ¡£åšæˆé—®ç­”ç³»ç»Ÿï¼Œæ¯”å¦‚ï¼šâ€œä¸Šä¼ å…¬å¸æ‰‹å†Œ â†’ é—®å®ƒå…¬å¸è¯·å‡åˆ¶åº¦â€ã€‚

ğŸ“Œ ç¤ºä¾‹ä»£ç ï¼š
```
#å‡è®¾ä½ å·²ç»æœ‰ä¸€ä¸ª PDF æ–‡æ¡£æˆ– txt æ–‡ä»¶ã€‚
from langchain.document_loaders import TextLoader
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# 1. åŠ è½½æ–‡æ¡£: æŠŠæ–‡æ¡£å˜æˆä¸€æ®µæ®µæ–‡æœ¬å—
loader = TextLoader("example.txt")
documents = loader.load()

# 2. è½¬å‘é‡ + å»ºç«‹å‘é‡åº“:    æŠŠæ–‡æ¡£ä¸­æ¯æ®µå†…å®¹å˜æˆå‘é‡ï¼Œå˜æˆä¸€ä¸ªå¯æ£€ç´¢çš„çŸ¥è¯†åº“
embeddings = OpenAIEmbeddings()
db = FAISS.from_documents(documents, embeddings)

# 3. æ„å»ºæ£€ç´¢é—®ç­”ç³»ç»Ÿï¼šretrieverç±»ä¼¼ä¸€ä¸ªæœç´¢å™¨ï¼Œåœ¨å‘é‡åº“ä¸­æŸ¥æ‰¾ç›¸å…³çš„æ®µè½ï¼›
# RetrievalQA æ˜¯å¤§æ¨¡å‹ + æ£€ç´¢çš„ç»„åˆé“¾ï¼ˆRAG æ¨¡å¼ï¼‰ï¼Œä½ é—®çš„é—®é¢˜ä¼šï¼š
## å…ˆå»â€œå‘é‡åº“â€é‡Œæ‰¾ç›¸å…³æ®µè½
## ç„¶åå†äº¤ç»™ OpenAI() å›ç­”
retriever = db.as_retriever()
qa = RetrievalQA.from_chain_type(llm=OpenAI(), retriever=retriever)

# 4. æé—®
print(qa.run("å…¬å¸è¯·å‡æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ"))
```

 ## ğŸ“ 5. VectorStoreï¼šå‘é‡åº“ï¼ˆä¾‹å¦‚ FAISSï¼‰

ğŸ‘‰ æŠŠæ–‡æœ¬è½¬æ¢æˆå‘é‡ï¼ˆEmbeddingï¼‰ï¼Œå­˜å…¥æ•°æ®åº“åå¯ä»¥â€œç›¸ä¼¼åŒ¹é…â€ã€‚

æ¯”å¦‚ï¼šä½ é—®â€œä¼‘å‡è§„åˆ™â€ï¼Œå®ƒå¯ä»¥ä»å‘é‡åº“é‡Œæ‰¾åˆ°æœ€ç›¸å…³çš„æ®µè½å†…å®¹ï¼Œå†ä¸¢ç»™ LLM å›ç­”ä½ ã€‚

å¸¸ç”¨å‘é‡åº“ï¼š
æœ¬åœ°ï¼šFAISSã€Chroma
äº‘ç«¯ï¼šPineconeã€Weaviate

